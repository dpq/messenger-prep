{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BUILT ON THE DEUS VULT VERSION; DISCARD IF IN DOUBT ##\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings\n",
    "\n",
    "import os, os.path\n",
    "import pandas as pd, numpy as np, scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import cufflinks as cf, matplotlib as mp\n",
    "cf.go_offline()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter \n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import dates\n",
    "from matplotlib.ticker import AutoMinorLocator, LinearLocator, AutoLocator\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy.signal import argrelextrema, find_peaks\n",
    "from functools import wraps\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "mp.rcParams['font.size'] = 22\n",
    "mp.rcParams['axes.labelsize'] = 32\n",
    "mp.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_M = 2440 # km\n",
    "M_0 = -1.96e02 * R_M**3 # nT. Alexeev, Belenkaya et al 2010 doi:10.1016/j.icarus.2010.01.024\n",
    "z_displacement = 484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 60\n",
    "resolutions = [60, 10, 5, 1]\n",
    "\n",
    "def load_data(resolution=60, year=None, mindoy=None, maxdoy=None):\n",
    "    if resolution not in resolutions:\n",
    "        print(\"Resolution not available, using 60sec averages\")\n",
    "        resolution = 60\n",
    "    \n",
    "    data_files = []\n",
    "    path = os.path.join(r'/home/mrmemcpy/myprojectdir/',\"%02d\" % resolution)\n",
    "   \n",
    "    for file in sorted(os.listdir(path)):\n",
    "        if year is None or file.startswith(\"MAGMSOSCIAVG\" + str(year % 2000)):\n",
    "            doy = int(file.split(\"_\")[0].replace(\"MAGMSOSCIAVG\" + str(year % 2000), \"\"), 10)\n",
    "            if (mindoy is None or doy >= mindoy) and (maxdoy is None or doy <= maxdoy):\n",
    "                data_files.append(pd.read_table(os.path.join(path, file), delim_whitespace=True, header=None))\n",
    "            if doy > maxdoy:\n",
    "                break\n",
    "\n",
    "    data = pd.concat(data_files, ignore_index=True)\n",
    "    data.columns = ['YEAR', 'DAY_OF_YEAR', 'HOUR', 'MINUTE', 'SECOND',\n",
    "        'TIME_TAG', 'NAVG', 'X_MSO', 'Y_MSO', 'Z_MSO', 'BX_MSO',\n",
    "        'BY_MSO', 'BZ_MSO', 'DBX_MSO', 'DBY_MSO', 'DBZ_MSO']\n",
    "    data['DATE'] = data.apply(lambda x: \n",
    "        datetime.strptime(\"%d-%03d_%02d:%02d:%02d\" % (x.YEAR, x.DAY_OF_YEAR, x.HOUR, x.MINUTE, x.SECOND),\n",
    "            \"%Y-%j_%H:%M:%S\"), axis=1)\n",
    "    data = data.drop(['YEAR', 'DAY_OF_YEAR', 'HOUR', 'MINUTE', 'SECOND', 'NAVG', 'TIME_TAG'], axis=1)\n",
    "    data = data.set_index('DATE')\n",
    "    grouped = data.groupby(level=0)\n",
    "    data = grouped.last()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_checkouts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7497537f2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Threshold manually chosen after careful examination of the resulting plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_checkouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutlier_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m550\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_checkouts' is not defined"
     ]
    }
   ],
   "source": [
    "# Threshold manually chosen after careful examination of the resulting plot\n",
    "data, bm = filter_checkouts(data, checkout, outlier_threshold=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ecaae041b4895a0c591e2009f7843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='resolution', options=(60, 10, 5, 1), value=60), IntSlider(value=20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(resolution=resolutions, year=(2011, 2015, 1), start_doy=(1, 365, 1), end_doy=(1, 365, 1))\n",
    "def w_load_data(resolution=resolution, year=2011, start_doy=91, end_doy=120):\n",
    "    data = load_data(resolution, year, start_doy, end_doy)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MESSENGER** data is available in multiple resolutions from 1 second averages to 60 second averages. Most of the calculations have been performed with 60-second resolution for speed; final results have been obtained on 5-second resolution data as that nearly matches the resolution capacity of our analytical model. \n",
    "\n",
    "Откалиброванный и усредненный набор данных располагается на ресурсе [PDS PPI](https://pds-ppi.igpp.ucla.edu/ditdos/download?id=pds://PPI/MESS-E_V_H_SW-MAG-4-SUMM-CALIBRATED-V1.0/DATA/MSO); для удобства дальнейшей обработки файлы данных из набора разделяются по интервалу усреднения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original MESSENGER data contains a number of artifacts. \n",
    "\n",
    "1. There are gaps in data that may lead to incorrectly calculated diffs if not approached with caution.\n",
    "1. There are spikes associated with the execution of checkout commands. These commands apply an artificial signal to the sensor so that sensor functionality and calibration can be verified. The checkouts occur nominally once per week, and the dates are noted in the documentation of the data set in the file MESS_MAGRDR_DS.CAT.\n",
    "\n",
    "These datapoints are filtered out and replaced with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyear, doy0, doy1 = 2013, 1, 365\n",
    "\n",
    "data = load_data(resolution, xyear, doy0, doy1)\n",
    "\n",
    "default_delta = np.timedelta64(resolution*10**9, 'ns')\n",
    "default_delta = np.timedelta64(60*10**9, 'ns') # 1 minute\n",
    "\n",
    "payload_columns = [\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\", \"X_MSO\", \"Y_MSO\", \"Z_MSO\"]\n",
    "\n",
    "\n",
    "def insert_gaps(data, gap_size):\n",
    "    gap_indices = np.where(np.diff(data.index) > default_delta)[0]\n",
    "    for i in gap_indices:\n",
    "        for c in payload_columns:\n",
    "            data.iat[i, data.columns.get_loc(c)] = np.nan\n",
    "        \n",
    "insert_gaps(data, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve and process the checkout dates, we first execute the following commands (BASH):\n",
    "\n",
    "    wget https://pds-ppi.igpp.ucla.edu/ditdos/viewFile?id=pds://PPI/MESS-E_V_H_SW-MAG-4-SUMM-CALIBRATED-V1.0/CATALOG/MESS_MAGRDR_DS.CAT -O MESS_MAGRDR_DS.CAT\n",
    "    sed -i 's/&nbsp;//g' MESS_MAGRDR_DS.CAT\n",
    "    grep -i checkout MESS_MAGRDR_DS.CAT  | grep '('  | sed 's/1Apr2005/01Apr2005/g' | sed 's/9Aug2005/09Apr2005/g' | awk '{ print substr($0, 0, 28)}' > checkout.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkout_dates(filename, first, last):\n",
    "    res = []\n",
    "    with open(filename) as f:\n",
    "        for l in f.readlines():\n",
    "            start, end = l[0:9], l[-15:-6]\n",
    "            start = datetime.strptime(start + \"-00:00:00\", '%d%b%Y-%H:%M:%S')\n",
    "            end = datetime.strptime(end + \"-23:59:59\", '%d%b%Y-%H:%M:%S')\n",
    "            if (end > first and start < last) or (start < last and start > first):\n",
    "                res.append((start, end))\n",
    "        return res\n",
    "\n",
    "checkout = load_checkout_dates('checkout.dat', data.index[0], data.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку калибровочные сигналы значительно различаются по амплитуде и иным характеристикам, производились нерегулярно, а в технической документации отсутствует информация по точному времени начала и окончания подачи индивидуальных калибровочных сигналов, недостающая информация была установлена с помощью анализа фрагментов массива данных, относящихся к суткам, в которые производилась калибровка.\n",
    "\n",
    "Статистический анализ отобранных данных показал, что продолжительность калибровочных сигналов не превышала трех минут, а  предполагаемая минимальная амплитуда сигнала составляла не менее 550нТл. Данные параметры в дальнейшем были использованы для автоматической выбраковки из общего массива данных измерений, совершенных в моменты времени, в которые были идентифицированы калибровочные сигналы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как установлено пороговое значение амплитуды магнитного поля, все измерения выше которого ассоциируются с калибровочными полями, за невозможностью восстановления фонового поля в отсутствие калибровочного сигнала производится фильтрация (удаление) соответствующих данных из массива. Во избежание ложных срабатываний фильтра обрабатываются только даты, заявленные в документации по калибровке магнитометра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_checkouts(data, checkout, outlier_threshold):\n",
    "    data = data.copy(True)\n",
    "    payload_columns = [\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]\n",
    "    for c in checkout:\n",
    "        outlier_indices = np.where(data.loc[c[0]:c[1]]['BX_MSO']**2 +\n",
    "                                   data.loc[c[0]:c[1]]['BY_MSO']**2 +\n",
    "                                   data.loc[c[0]:c[1]]['BZ_MSO']**2 > outlier_threshold**2)[0]\n",
    "        for i in outlier_indices:\n",
    "            iprev = data.loc[c[0]:c[1]].index[i-1]\n",
    "            inext = data.loc[c[0]:c[1]].index[i+1]\n",
    "            i = data.loc[c[0]:c[1]].index[i]\n",
    "            for col in payload_columns:\n",
    "                for j in [iprev, i, inext]:\n",
    "                    data.at[j, col] = np.nan\n",
    "    bms = []\n",
    "    for c in checkout:\n",
    "        bms.append(np.array(np.sqrt(\n",
    "            data.loc[c[0] : c[1]]['BX_MSO']**2 +\n",
    "            data.loc[c[0] : c[1]]['BY_MSO']**2 +\n",
    "            data.loc[c[0] : c[1]]['BZ_MSO']**2)\n",
    "        ))\n",
    "        bmx = bms[-1][~np.isnan(bms[-1])]\n",
    "    if len(bms) > 0:\n",
    "        bm = np.concatenate(bms)\n",
    "        bm = bm[~np.isnan(bm)]\n",
    "    else:\n",
    "        bm = []\n",
    "    return data, bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daecc6970f3a4b109eb627f704c120e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=100.0, description='outlier_threshold', max=1000.0, min=100.0, step=10…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(data=fixed(data), checkout=fixed(checkout), outlier_threshold=widgets.FloatSlider(min=100, max=1000, step=10, continuousUpdate=False))\n",
    "def w_filter_checkouts(**kwargs):\n",
    "    _, bm = filter_checkouts(**kwargs)\n",
    "    plt.hist(bm, 100, log=True);\n",
    "    plt.xlabel('$|B|$');\n",
    "    plt.ylabel('$\\log\\,N$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['R'] = np.sqrt((data.X_MSO**2+data.Y_MSO**2+data.Z_MSO**2))\n",
    "data['RXY'] = np.sqrt((data.X_MSO**2+data.Y_MSO**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrmemcpy/myprojectdir/myprojectenv/lib/python3.6/site-packages/scipy/signal/_peak_finding.py:77: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in less\n",
      "\n",
      "/home/mrmemcpy/myprojectdir/myprojectenv/lib/python3.6/site-packages/scipy/signal/_peak_finding.py:78: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in less\n",
      "\n",
      "/home/mrmemcpy/myprojectdir/myprojectenv/lib/python3.6/site-packages/scipy/signal/_peak_finding.py:77: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater\n",
      "\n",
      "/home/mrmemcpy/myprojectdir/myprojectenv/lib/python3.6/site-packages/scipy/signal/_peak_finding.py:78: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with warnings.catch_warnings(record=True) as w:\n",
    "#warnings.simplefilter(\"always\")\n",
    "df_apsis = pd.concat([\n",
    "    pd.DataFrame(data.R.iloc[argrelextrema(data.R.values, np.less)].rename(\"Periapsis\")),\n",
    "    pd.DataFrame(data.R.iloc[argrelextrema(data.R.values, np.greater)].rename(\"Apoapsis\"))],\n",
    "    axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c81f34b89f4a28a0cbbbf1514676c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(df_apsis=fixed(df_apsis))\n",
    "def apsis_plot(df_apsis):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    lines = {'Periapsis': 'Высота перицентра', 'Apoapsis': 'Высота апоцентра'}\n",
    "    for k in lines.keys():\n",
    "        line = df_apsis[~np.isnan(df_apsis[k])]\n",
    "        fig.add_trace(go.Scatter(x=line.index, y=line[k].values,\n",
    "                    mode='lines+markers',\n",
    "                    name=lines[k]))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=go.layout.Title(\n",
    "            text=\"Апсиды орбиты КА MESSENGER ({:%Y-%m-%d} - {:%Y-%m-%d})\".format(\n",
    "                min(df_apsis.index), max(df_apsis.index)\n",
    "            ), x=0.5, xanchor='center'),\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=\"Дата\")),\n",
    "        yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=\"Высота [км]\")),\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dipole_field(data, psi=0.0):\n",
    "    data = data.copy(True)\n",
    "    x, y, z = data.X_MSO, data.Y_MSO, (data.Z_MSO - z_displacement)\n",
    "\n",
    "    # Distance of the spacecraft to Mercury's center in km\n",
    "    data[\"R_DIPOLE\"]=np.sqrt(x**2 + y**2 + z**2)\n",
    "    \n",
    "    # hermomagnetic colatitude in radians\n",
    "    data[\"THETA_DIPOLE\"]=np.arccos(z/data.R_DIPOLE)\n",
    "    # hermomagnetic latitude in radians\n",
    "    data[\"LAMBDA_DIPOLE\"]=np.arcsin(z/data.R_DIPOLE)\n",
    "        \n",
    "    p = z*np.cos(psi) - x*np.sin(psi)\n",
    "    Br = M_0/data.R_DIPOLE**5\n",
    "    data[\"BX_DIPOLE\"]=-Br*(- data.R_DIPOLE**2 *np.sin(psi) - 3.*x*p)\n",
    "    data[\"BY_DIPOLE\"]= Br*(3.*y*p)\n",
    "    data[\"BZ_DIPOLE\"]=-Br*(data.R_DIPOLE**2 *np.cos(psi) - 3.*z*p)\n",
    "    data[\"BABS_DIPOLE\"]=np.abs(M_0)/ data.R_DIPOLE**4 * np.sqrt(3*z**2 + data.R_DIPOLE**2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de0c0f29a264d798389f72c2dbf81a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='psi', max=3.141592653589793…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(data=fixed(data), psi=widgets.FloatSlider(min=-np.pi, max=np.pi, step=np.pi/15, continuous_update=False))\n",
    "def w_dipole_field(**kwargs):\n",
    "    df_dipole = dipole_field(**kwargs)[100:250]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    lines = {\"BX\": \"$B_x$\", \"BY\": \"$B_y$\", \"BZ\": \"$B_z$\", \"BABS\": \"$|B|$\"}\n",
    "    colors = ['black', 'red', 'green', 'blue']\n",
    "    for component, color in zip(sorted(lines.keys()), colors):\n",
    "        field = df_dipole[~np.isnan(df_dipole['{}_DIPOLE'.format(component)])]\n",
    "        fig.add_trace(go.Scatter(x=field.index, y=field['{}_DIPOLE'.format(component)].values, \n",
    "                mode='lines', hoverinfo='x+y',\n",
    "                name=lines[component], marker_color=color))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=go.layout.Title(\n",
    "            text=r\"$\\text{{Магнитное поле диполя вдоль орбиты КА MESSENGER ({:%Y-%m-%d} - {:%Y-%m-%d}). }} \\psi={}$\".format(\n",
    "                min(df_dipole.index), max(df_dipole.index), kwargs['psi']\n",
    "            ), x=0.5, xanchor='center'),\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=\"Дата\")),\n",
    "        yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=\"B [nT]\")),\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы учесть ряд эффектов, связанных с состоянием межпланетной среды и высоким эксцентриситетом орбиты Меркурия, необходимо было получить почасовой массив векторов положения и скорости Меркурия в солнечно-эклиптических координатах с помощью Telnet-ресурса проекта [NASA JPL Horizons](http://ssd.jpl.nasa.gov/horizons.cgi). Помимо прочего, данный проект предоставляет доступ к результатам вычислений эфемерид большого количества небесных тел Солнечной системы, подготовленным с помощью системы [NAIF SPICE](https://naif.jpl.nasa.gov/naif/). Процесс извлечения необходимых данных через Telnet автоматизирован с помощью вспомогательного программного обеспечения.\n",
    "\n",
    "    ./heliocoord.py Mercury 2011-Mar-23Z00:00 2015-Apr-30Z23:59 1h > mercury-pos-hr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mercury_horizons(resolution=60, year=None, mindoy=None, maxdoy=None):\n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%Y-%b-%dZ%H:%M:%S.0000')\n",
    "    data = pd.read_table(\"mercury-pos-min.txt\", sep=\"\\t\", engine='python', parse_dates=[0], date_parser=dateparse)\n",
    "    data.columns = [\"DATE\", \"X\", \"Y\", \"Z\", \"VX\", \"VY\", \"VZ\"]\n",
    "    data = data.drop_duplicates(\"DATE\")\n",
    "    data = data.set_index('DATE')\n",
    "    \n",
    "    if year is not None:\n",
    "        data = data[data.index.year == year]\n",
    "    if mindoy is not None:\n",
    "        data = data[data.index.dayofyear >= mindoy]\n",
    "    if maxdoy is not None:\n",
    "        data = data[data.index.dayofyear <= maxdoy]\n",
    "    \n",
    "    if resolution != 60:\n",
    "        data = data.resample('{}S'.format(resolution)).ffill()\n",
    "    \n",
    "    data['VABS'] = np.sqrt(data.VX**2 + data.VY**2 + data.VZ**2)\n",
    "    data['D'] = np.sqrt(data.X**2 + data.Y**2 + data.Z**2)\n",
    "    return data.sort_index()\n",
    "\n",
    "\n",
    "data = pd.concat([data, load_mercury_horizons(resolution, xyear, doy0, doy1)], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке изображена проекция орбиты Меркурия в гелиографическо-инерциальной системе. Координаты планеты получены с помощью сервиса [NASA Omniweb](https://omniweb.gsfc.nasa.gov/coho/helios/planet.html). Наклонение орбиты Меркурия относительно плоскости солнечного экватора составляет около 6.3град, что в несколько раз превышает наклонения орбит всех остальных планет. Одним из следствий подобной конфигурации орбиты является трудность наблюдения транзитов Меркурия по диску Солнца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mercury-pos-hgi.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fb112233eb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmercury_hgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mercury_hgi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-fb112233eb33>\u001b[0m in \u001b[0;36mload_mercury_hgi\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_mercury_hgi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmercury_hgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mercury-pos-hgi.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\s*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HGI_LON\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HGI_LON\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HGI_LAT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HG_LAT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AU\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HGI_LON\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmercury_hgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HGI_LAT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0;34m' \"python-fwf\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 )\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m         )\n\u001b[1;32m   2295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myprojectdir/myprojectenv/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mercury-pos-hgi.txt'"
     ]
    }
   ],
   "source": [
    "def load_mercury_hgi():\n",
    "    mercury_hgi = pd.read_table(\"mercury-pos-hgi.txt\", sep=r'\\s*', engine='python')\n",
    "    mercury_hgi[\"HGI_LON\"] = mercury_hgi[\"HGI_LON\"] * np.pi/180\n",
    "    mercury_hgi[\"HGI_LAT\"] = (90-mercury_hgi[\"HG_LAT\"]) * np.pi/180\n",
    "    mercury_hgi[\"X\"] = mercury_hgi[\"AU\"]*np.cos(mercury_hgi[\"HGI_LON\"])*np.sin(mercury_hgi[\"HGI_LAT\"])\n",
    "    mercury_hgi[\"Y\"] = mercury_hgi[\"AU\"]*np.sin(mercury_hgi[\"HGI_LON\"])*np.sin(mercury_hgi[\"HGI_LAT\"])\n",
    "    mercury_hgi[\"Z\"] = mercury_hgi[\"AU\"]*np.cos(mercury_hgi[\"HGI_LAT\"])\n",
    "    mercury_hgi['DATE'] = mercury_hgi.apply( lambda x: pd.datetime(year=int(x['YYYY']), month=1, day=1) +  timedelta(days=(int(x['DOY'])-1)), axis=1)\n",
    "    mercury_hgi = mercury_hgi.set_index(\"DATE\")\n",
    "    return mercury_hgi\n",
    "\n",
    "mercury_hgi = load_mercury_hgi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(date=widgets.SelectionSlider(\n",
    "    options=list(map(lambda x: x.strftime('%Y-%m-%d'), mercury_hgi.index)),\n",
    "    continuous_update=False\n",
    "))\n",
    "def plot_mercury_position(date):\n",
    "    orbit = go.Scatter3d(\n",
    "        # 88 = Hermean year duration\n",
    "        x=mercury_hgi[:88+1].X, y=mercury_hgi[:88+1].Y, z=mercury_hgi[:88+1].Z, mode='lines', name=\"Orbit\",\n",
    "        line=dict(\n",
    "            color='#1f77b4',\n",
    "            width=4\n",
    "        )\n",
    "    )\n",
    "\n",
    "    sun = go.Scatter3d(x=[0], y=[0], z=[0], mode='markers', name='Sun')\n",
    "    planet = go.Scatter3d(x=[mercury_hgi.X[date]], y=[mercury_hgi.Y[date]], z=[mercury_hgi.Z[date]], mode='markers', name=\"Mercury\")\n",
    "\n",
    "    layout = dict(\n",
    "        width=900,\n",
    "        height=700,\n",
    "        autosize=False,\n",
    "        title='Mercury position and orbit',\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                eye=dict(x=-3, y=2, z=2)\n",
    "            ),\n",
    "            aspectratio=dict(x=1, y=1, z=1),\n",
    "            aspectmode='data',\n",
    "            xaxis_title='X [a.u.]',\n",
    "            yaxis_title='Y [a.u.]',\n",
    "            zaxis_title='Z [a.u.]',\n",
    "        )\n",
    "    )\n",
    "    fig = dict(data=[orbit, sun, planet], layout=layout)\n",
    "    cf.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.subplot()\n",
    "#ax.plot(hgi_x, hgi_y);\n",
    "#ax.scatter(0,0, color='r', s=240); # Position of the Sun\n",
    "#plt.xlabel(\"HGI X [а.е.]\")\n",
    "#plt.ylabel(\"HGI Y [а.е.]\")\n",
    "#ax.set_aspect('equal', adjustable='box');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.subplot()\n",
    "#ax.plot(hgi_x, hgi_z)\n",
    "#ax.scatter(0,0, color='r', s=240); # Position of the Sun\n",
    "#plt.xlabel(\"HGI X [а.е.]\")\n",
    "#plt.ylabel(\"HGI Z [а.е.]\")\n",
    "#ax.set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WITH CAUTION #\n",
    "#backup_mess = data.copy(deep=True)\n",
    "#backup_merc = mercury_xyz.copy(deep=True)\n",
    "#print(backup_mess.shape,  backup_merc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WITH CAUTION #\n",
    "#data = backup_mess.copy(deep=True)\n",
    "#mercury_xyz = backup_merc.copy(deep=True)\n",
    "#print(backup_mess.shape,  backup_merc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE WITH CAUTION #\n",
    "#del backup_merc\n",
    "#del backup_mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extrema(data):\n",
    "    x, y, z, r, rxy = 'X_MSO', 'Y_MSO', 'Z_MSO', 'R', 'RXY'\n",
    "    \n",
    "    periapsis = find_peaks(1/data[r].values[~np.isnan(data[r].values)].round(0))[0]\n",
    "    \n",
    "    extrema=pd.DataFrame(index=data.index)\n",
    "    extrema['TYPE']=0\n",
    "    \n",
    "    xy_edges = find_peaks(data[rxy].round(0).values[~np.isnan(data[rxy].values)])[0]\n",
    "    \n",
    "    if xy_edges[0] < periapsis[0] and xy_edges[1] > periapsis[0]:\n",
    "        xy_edges = xy_edges[1:]\n",
    "    xy1, xy2 = xy_edges[1::2], xy_edges[0::2]\n",
    "    \n",
    "    #extrema.iloc[xy_edges] = 1\n",
    "    extrema.iloc[xy1] = 1\n",
    "    extrema.iloc[xy2] = -1\n",
    "    \n",
    "    cosine_array = pd.DataFrame(index=data.index)\n",
    "    cosine_array['VALUE'] = np.nan\n",
    "    \n",
    "    size = np.min([len(data[x].iloc[xy1].values), len(data[x].iloc[xy2].values)])\n",
    "    \n",
    "    dx = np.abs(data[x].iloc[xy1].values[:size] - data[x].iloc[xy2].values[:size])\n",
    "    dx *= np.sign(data[x].iloc[xy1].values[:size]  - data[x].iloc[xy2].values[:size] )\n",
    "    dy = data[y].iloc[xy1].values[:size] - data[y].iloc[xy2].values[:size]\n",
    "    cosine = np.cos(np.arctan2(dy, dx))\n",
    "\n",
    "    max_delta_cosine = 0.06 # Empirically chosen to cut off rogue data points\n",
    "    cosine_diff = np.abs(np.diff(np.abs(cosine)))\n",
    "    cosine[np.append(cosine_diff > max_delta_cosine, False)] = np.nan\n",
    "    \n",
    "    i_from, i_to = extrema.iloc[periapsis].index, extrema.iloc[periapsis].index[1:]\n",
    "    i_to = i_to\n",
    "    for i in range(len(i_to)):\n",
    "        cosine_array.loc[i_from[i] : i_to[i]]['VALUE'] = cosine[i]\n",
    "    cosine_array.loc[i_to[-1]:]['VALUE'] = cosine[-1]\n",
    "    return extrema, cosine_array\n",
    "\n",
    "\n",
    "def show_extrema(data):\n",
    "    plot_size = 350000\n",
    "    plt.plot((data.R[:plot_size])/max(data.R[:plot_size]), label=r'Относительное расстояние $R/R_{max}$')\n",
    "    plt.plot(data.EXTREMA[:plot_size]/2, 'black', label=r'Экстремумы $R_{XY}$')\n",
    "    plt.plot(data.COSALPHA[:plot_size], 'green', label=r'$\\cos\\,\\alpha$')\n",
    "    plt.xlabel(\"Дата\")\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.legend()\n",
    "    \n",
    "def show_extrema(data, plot_size=350000):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=((data.R[:plot_size])/max(data.R[:plot_size])).values, \n",
    "        mode='lines', hoverinfo='x+y',\n",
    "        name=r'$R/R_{max}$', marker={'color':'navy'}\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=(data.EXTREMA[:plot_size]/5).T.values[0],\n",
    "        mode='lines', hoverinfo='x',\n",
    "        name=r'Экстремумы $R_{XY}$', marker={'color':'orange'}\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data.COSALPHA[:plot_size].T.values[0], \n",
    "        mode='lines', hoverinfo='x+y',\n",
    "        name=r'$\\cos\\,\\alpha$', marker={'color':'green'}\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=go.layout.Title(\n",
    "            text=r\"$\\text{{Апсиды орбиты КА MESSENGER и фаза орбиты Меркурия ({:%Y-%m-%d} - {:%Y-%m-%d}). }}$\".format(\n",
    "                min(data.index), max(data.index)\n",
    "            ), x=0.5, xanchor='center'),\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=\"Дата\"))\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EXTREMA'], data['COSALPHA'] = find_extrema(data)\n",
    "#show_extrema(data, 24*60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodes(data):\n",
    "    extrema=pd.DataFrame(index=data.index)\n",
    "    extrema['TYPE']=0\n",
    "\n",
    "    apoapsis = find_peaks(data.R.values.round(0))[0]\n",
    "    periapsis = find_peaks(1/data.R.values.round(0))[0]\n",
    "\n",
    "    extrema.iloc[apoapsis] = 2\n",
    "    extrema.iloc[periapsis] = 1\n",
    "    return extrema, apoapsis, periapsis\n",
    "\n",
    "nodes, _, _ = find_nodes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_periapo(symbol=\"\", first=0, last=None):\n",
    "    nodes, apoapsis, periapsis = find_nodes(data)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    xy = [[0, 0]]\n",
    "    r = 2400\n",
    "    kwargs = {'type': 'circle', 'xref': 'x', 'yref': 'y', 'fillcolor': 'orange', 'layer': 'below'}\n",
    "    points = [go.layout.Shape(x0=-r, y0=-r, x1=r, y1=r, **kwargs)]\n",
    "    fig.update_layout(shapes=points)\n",
    "\n",
    "    frag = data.iloc[apoapsis][first:last]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=frag.X_MSO.values,\n",
    "        y=frag.Y_MSO.values,\n",
    "        name=\"APO\",\n",
    "        mode=\"markers\", marker={'color':'red'}\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    frag = data.iloc[periapsis][first:last]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=frag.X_MSO.values,\n",
    "        y=frag.Y_MSO.values,\n",
    "        name=\"PERI\",\n",
    "        mode=\"markers\", marker={'color':'blue'}\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=go.layout.Title(\n",
    "            text=r\"$\\text{{Проекция апсидов орбиты КА MESSENGER на плоскость XY ({:%Y-%m-%d} - {:%Y-%m-%d}). }}$\".format(\n",
    "                min(data.index), max(data.index)\n",
    "            ), x=0.5, xanchor='center'),\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=r\"MSO\" + symbol + \" X [км]\")),\n",
    "        yaxis=go.layout.YAxis(\n",
    "            title=go.layout.yaxis.Title(text=r\"MSO\" + symbol + \" Y [км]\"),\n",
    "            scaleanchor=\"x\",\n",
    "            scaleratio=1\n",
    "        ),\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    #plt.xlabel()\n",
    "    #plt.ylabel(r\"MSO\" + symbol + \" Y [км]\")\n",
    "    #plt.legend();\n",
    "    \n",
    "show_periapo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем анализе допущен ряд упрощений и приближений. Во-первых, перед кластеризацией профилей магнитометра из данных вычитается магнитное поле диполя Меркурия (B0=196нТл, z0=484км в сторону северного полушария; наклоном диполя около 3град в первом приближении мы пренебрегаем), чтобы усилить влияние вкладов магнитосферных токовых систем на результат кластеризации. Во-вторых, за неимением прямых измерений параметров солнечного ветра для расчёта угла аберрации используется среднее значение скорости протонов на 0.3-0.4 а.е., полученное на КА Helios-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rotate the coordinate system in order to acknowledge the fact that Mercury's own velocity is about 10% of solar wind velocity and is directed normally to MSO X axis. Solar wind velocity is taken constant at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of solar wind speeds during solar minimum: Calibration for numerical solar wind modeling constraints on the source of the slow solar wind\n",
    "# S. L. McGregor  W. J. Hughes  C. N. Arge  M. J. Owens  D. Odstrcil\n",
    "# https://doi.org/10.1029/2010JA015881\n",
    "    \n",
    "sw_velocity = 350 # km/s\n",
    "# TODO: this is a crude approximation; investigate ways to improve it\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    c, s = np.cos(theta.values), np.sin(theta.values)\n",
    "    np.ndarray(shape=(c.shape[0], 3, 3), dtype=float, order='F')\n",
    "    R = np.vstack([[c, -s, [0]*c.shape[0]],\n",
    "                   [s, c, [0]*c.shape[0]],\n",
    "                   [[0]*c.shape[0], [0]*c.shape[0], [1]*c.shape[0]]\n",
    "                  ])\n",
    "    return R\n",
    "\n",
    "def aberrate(data, sw_velocity):\n",
    "    data = data.copy(True)\n",
    "    data['ABERRATION_ANGLE'] = -np.arctan2(sw_velocity, data.VABS)\n",
    "    rot = rotation_matrix(data['ABERRATION_ANGLE'][:data.shape[0]]).reshape(3, 3, data.shape[0]).transpose(2,0,1)\n",
    "\n",
    "    triads = [\n",
    "        ['X_MSO', 'Y_MSO', 'Z_MSO'],\n",
    "        ['BX_MSO', 'BY_MSO', 'BZ_MSO'],\n",
    "        ['DBX_MSO', 'DBY_MSO', 'DBZ_MSO']\n",
    "    ]\n",
    "\n",
    "    for t in triads:\n",
    "        vec = np.array([ data[t].values[:data.shape[0]] ]).transpose(0,2,1)\n",
    "        resx = np.matmul(rot, vec.T).reshape(data.shape[0], 3)\n",
    "        for i in range(len(t)):\n",
    "            data[t[i]] = resx.T[i]\n",
    "    return data\n",
    "\n",
    "#data = aberrate(data, sw_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duskdawn = nodes[nodes[\"TYPE\"]==1]\n",
    "# coses = data.COSALPHA[(~np.isnan(data.COSALPHA.VALUE)) & (np.abs(data.COSALPHA.VALUE) < 0.05)].index\n",
    "# duskdawn = duskdawn.index.intersection(coses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_orbit_data(data, nodes, orbit_no):\n",
    "    ep = 100\n",
    "    bx, by, bz = -43, 13, 0\n",
    "    periapsis = nodes[nodes[\"TYPE\"]==1]\n",
    "    dt00 = periapsis.index[orbit_no] - pd.Timedelta(\"4h\")\n",
    "    dt01 = periapsis.index[orbit_no] - pd.Timedelta(\"120m\")\n",
    "    dt10 = periapsis.index[orbit_no] + pd.Timedelta(\"120m\")\n",
    "    dt11 = periapsis.index[orbit_no] + pd.Timedelta(\"4h\")\n",
    "    fragment0 = data[dt00:dt01].copy(True)\n",
    "    fragment1 = data[dt10:dt11].copy(True)    \n",
    "    rmse=np.mean([\n",
    "        np.std(fragment0.BX_MSO),\n",
    "        np.std(fragment0.BY_MSO),\n",
    "        np.std(fragment0.BZ_MSO),\n",
    "        np.std(fragment1.BX_MSO),\n",
    "        np.std(fragment1.BY_MSO),\n",
    "        np.std(fragment1.BZ_MSO)\n",
    "                 ])\n",
    "\n",
    "    if (math.fabs(np.mean(fragment0.BX_MSO)-np.mean(fragment1.BX_MSO))<ep and \n",
    "        math.fabs(np.mean(fragment0.BY_MSO)-np.mean(fragment1.BY_MSO))<ep and \n",
    "        math.fabs(np.mean(fragment0.BZ_MSO)-np.mean(fragment1.BZ_MSO))<ep):\n",
    "        return rmse\n",
    "            \n",
    "        print(rmse)\n",
    "\n",
    "min_i, min_abs = -1, 9999\n",
    "for i in range(1090):\n",
    "    absx = sw_orbit_data(data, nodes, i)\n",
    "    if  absx < min_abs:\n",
    "        min_abs = absx\n",
    "        min_i = i\n",
    "        \n",
    "\n",
    "print(min_i, min_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = orbit_data(data, nodes, min_i)\n",
    "exp.X_MSO = exp.X_MSO*1e3\n",
    "exp.Y_MSO = exp.Y_MSO*1e3\n",
    "exp.Z_MSO = exp.Z_MSO*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_data(data, nodes, min_i)[[\"X_MSO\", \"Y_MSO\", \"Z_MSO\", \"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]].to_csv(\"messenger_compare.csv\".format(xyear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orbit_data(data, nodes, orbit_no):\n",
    "    periapsis = nodes[nodes[\"TYPE\"]==1]\n",
    "    dt1 = periapsis.index[orbit_no] - pd.Timedelta(\"120m\")\n",
    "    dt2 = periapsis.index[orbit_no] + pd.Timedelta(\"120m\")\n",
    "    fragment = data[dt1:dt2].copy(True)\n",
    "    fragment[\"BABS\"] = np.sqrt(fragment.BX_MSO**2 + fragment.BY_MSO**2 + fragment.BZ_MSO**2)\n",
    "    return fragment\n",
    "    \"\"\"\n",
    "    timex = list(\n",
    "        map(\n",
    "            lambda dt64: datetime.utcfromtimestamp((dt64 - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')),\n",
    "            fragment.index.values\n",
    "        )\n",
    "    )\n",
    "    x, y, z = fragment.X_MSO, fragment.Y_MSO, fragment.Z_MSO\n",
    "    bx, by, bz = fragment.BX_MSO, fragment.BY_MSO, fragment.BZ_MSO\n",
    "    dbx, dby, dbz = fragment.DBX_MSO, fragment.DBY_MSO, fragment.DBZ_MSO\n",
    "    r, rxy = fragment.R, fragment.RXY\n",
    "            \n",
    "    coords = np.vstack([x, y, z])\n",
    "    values = np.vstack((bx, by, bz))\n",
    "    err  = np.vstack([dbx, dby, dbz])\n",
    "    babs = np.sqrt(bx**2 + by**2 + bz**2)\n",
    "    # lo, hi = values - err, values + err\n",
    "    return timex, coords, values, err, babs\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def advplot(fragment, more_title=\"\"):    \n",
    "    fig = make_subplots(rows=2,\n",
    "                        cols=1,\n",
    "                        subplot_titles=[\"Magnetic field\", \"Coordinates\"],\n",
    "                        shared_xaxes=False,\n",
    "                        shared_yaxes=False)\n",
    "    \n",
    "    \n",
    "    lo = fragment[[\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]] - fragment[[\"DBX_MSO\", \"DBY_MSO\", \"DBZ_MSO\"]].to_numpy()\n",
    "    hi = fragment[[\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]] + fragment[[\"DBX_MSO\", \"DBY_MSO\", \"DBZ_MSO\"]].to_numpy()\n",
    "    \n",
    "    s4=go.Scatter(\n",
    "            x=pd.concat([pd.Series(fragment.index.values), pd.Series(fragment.index.values)]),\n",
    "            y=pd.concat([fragment.BABS, -fragment.BABS]),\n",
    "            mode='lines',\n",
    "            name=r\"$|B|$\",\n",
    "            marker_color='black',\n",
    "        )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        s4,\n",
    "        row=1,\n",
    "        col=1\n",
    "        )\n",
    "    s4.on_click(update_point)\n",
    "    \n",
    "    for i, j, c in zip([\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"], [\"X_MSO\", \"Y_MSO\", \"Z_MSO\"], ['red', 'green', 'blue']):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fragment.index,\n",
    "                y=lo[i],\n",
    "                line=dict(width=0), \n",
    "                mode='lines',\n",
    "                opacity=0.0,\n",
    "                name=i.split(\"_\")[0][-1],\n",
    "                marker_color=c,\n",
    "                fillcolor=c,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fragment.index,\n",
    "                y=hi[i],\n",
    "                mode='lines',\n",
    "                line=dict(width=0),\n",
    "                opacity=0.0,\n",
    "                name=i.split(\"_\")[0][-1],\n",
    "                marker_color=c,\n",
    "                showlegend=False,\n",
    "                fill='tonexty'\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "    \n",
    "        s3=go.Scatter(\n",
    "                       x=fragment.index,\n",
    "                       y=fragment[i],\n",
    "                       mode='lines',\n",
    "                       name=i.split(\"_\")[0][-1],\n",
    "                       marker_color=c\n",
    "                      )  \n",
    "               \n",
    "        fig.add_trace(\n",
    "                   s3,\n",
    "                   row=1\n",
    "                   col=1\n",
    "                    )\n",
    "        s3.on_click(update_point)\n",
    "        \n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=fragment.index,\n",
    "                y=fragment[j],\n",
    "                mode='lines',\n",
    "                name=j,\n",
    "                marker_color=c,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1\n",
    "        )\n",
    "        \n",
    "    fig.show()\n",
    "   \n",
    "    \n",
    "def export_orbit(nodes, orbit_no, normalize=False, more_title=\"\"):\n",
    "    timex, coord, values, err, babs = orbit_data(nodes, orbit_no, normalize)\n",
    "    \n",
    "    pd.to_csv(\"orbit_{:04d}.dat\".format(orbit_no + 1), date_format=\"%Y %m %d %H %M %S\")\n",
    "    \n",
    "    f = open(fname, 'wb')\n",
    "    for i in range(len(fragment)):\n",
    "        line = \" {} {:>13} {:>9} {:>9} {:>7} {:>7} {:>7}\\n\".format(fragment.index[i].strftime(\"%Y %m %d %H %M %S\"), \"{:.2f}\".format(fragment.X_MSO[i]), \"{:.2f}\".format(fragment.Y_MSO[i]), \"{:.2f}\".format(fragment.Z_MSO[i]), \"{:.2f}\".format(fragment.BX_MSO[i]), \"{:.2f}\".format(fragment.BY_MSO[i]), \"{:.2f}\".format(fragment.BZ_MSO[i]))\n",
    "        f.write(line.encode('utf8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advplot(orbit_data(data, nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "    \"\"\"\n",
    "    with plt.style.context(('classic')):\n",
    "        mp.rcParams['font.size'] = 22\n",
    "        mp.rcParams['axes.labelsize'] = 32\n",
    "        #mp.rcParams['figure.figsize'] = (15, 10)\n",
    "        fig = plt.figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "        ax = fig.add_subplot(211)\n",
    "        plt.grid(which='minor')\n",
    "        plt.grid(which='major')\n",
    "        plt.subplots_adjust(bottom=-1.0)\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=\"vertical\")\n",
    "        if more_title != \"\":\n",
    "            more_tile = \" :: \" + more_title\n",
    "        plt.title(\"%s%s\" % (timex[0].strftime(\"%Y-%m-%d\"), more_title))\n",
    "\n",
    "        #labels = { \"coord\": [r\"$X_{MSO}$\", r\"$Y_{MSO}$\", r\"$Z_{MSO}$\"], \"bfield\": [r\"$B_x$\", r\"$B_y$\", r\"$B_z$\"]}\n",
    "        #colors = [\"red\", \"green\", \"blue\"]\n",
    "        #lines = []\n",
    "        #for i in range(values.shape[0]):\n",
    "        #    line = ax.plot(timex, values[i], label=labels[\"bfield\"][i], color=colors[i])\n",
    "        #    lines.append(line)\n",
    "        #ax.plot(timex, babs, color='k', linewidth=1.4)\n",
    "        #ax.plot(timex, -babs, color='k', linewidth=1.4)\n",
    "        \n",
    "        \n",
    "        plt.ylabel(\"Магнитное поле [нТл]\")\n",
    "        diffax = ax.twinx()\n",
    "        \n",
    "\n",
    "        deltab = np.abs(np.diff(babs))\n",
    "        diffax.set_ylim((0, np.max(deltab)*2))\n",
    "        line = diffax.plot(timex[:-1], deltab, color='magenta', label=r'$\\Delta$B')\n",
    "        lines.append(line)\n",
    "        for tl in diffax.get_yticklabels():\n",
    "            tl.set_color('magenta')\n",
    "        diffax.set_ylabel(r'$|\\Delta B_{abs}|$ [нТл]', color='magenta')\n",
    "        #lines = lines[0] + lines[1] + lines[2] + lines[3]\n",
    "    \n",
    "        ax.xaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "\n",
    "        ax = fig.add_subplot(212)\n",
    "        plt.grid(which='minor')\n",
    "        plt.grid(which='major')\n",
    "        ax.xaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=\"vertical\")\n",
    "        plt.xlabel(\"Время\")\n",
    "        plt.ylabel(\"Расстояние [км]\")\n",
    "        #ax.plot(fragment.RHO_DIPOLE, color='k', linewidth=2, label=r'$\\rho_{D}$')\n",
    "        for i in range(coords.shape[0]):\n",
    "            line = ax.plot(timex, coords[i], label=labels[\"coord\"][i], color=colors[i])\n",
    "            lines.append(line)\n",
    "        ax.legend()\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_orbit = 0\n",
    "for i in range(nodes[nodes.TYPE==1].shape[0]):\n",
    "    export_orbit(nodes, first_orbit + i, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[\"BZ_MSO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://ccmc.gsfc.nasa.gov/RoR_WWW/presentations/Dipole.pdf\n",
    "# rho   - total distance of the spacecraft to Mercury's center in km\n",
    "# theta - hermomagnetic latitude in radians (NOT degrees)\n",
    "# B_0   - hermomagnetic dipole field approximation\n",
    "# Bx = 3M xz/r^5\n",
    "# By = 3M yz/r^5\n",
    "# Bz = M (3z^2-r^2)/r^5\n",
    "\n",
    "#data[\"BABS_DIPOLE\"]=np.abs(M_0)*np.sqrt(1 + 3*np.cos(data.THETA_DIPOLE)**2) / data.RHO_DIPOLE**3\n",
    "#data[\"BX_DIPOLE\"]=3*M_0*z*x / data.RHO_DIPOLE**5\n",
    "#data[\"BY_DIPOLE\"]=3*M_0*z*y / data.RHO_DIPOLE**5\n",
    "#data[\"BZ_DIPOLE\"]=M_0*(3*z**2 - data.RHO_DIPOLE**2)/data.RHO_DIPOLE**5\n",
    "    \n",
    "# Do not modify the data array, just calc along what's been given\n",
    "def dipole_profile(coords, psi, offset_x, offset_y, offset_z):\n",
    "    x, y, z = coords.X_AB + offset_x, coords.Y_AB + offset_y, coords.Z_AB + offset_z\n",
    "    #if aberrated:\n",
    "    #    x, y, z = data.X_AB + offset[0], data.Y_AB + offset[1], data.Z_AB + offset[2]\n",
    "    #else:\n",
    "    #    x, y, z = data.X_MSO + offset[0], data.Y_MSO + offset[1], data.Z_MSO + offset[2]\n",
    "    rho=np.sqrt(x**2 + y**2 + z**2)\n",
    "    theta=np.arcsin(z/rho)    \n",
    "    babs=np.abs(M_0)/ rho**4 * np.sqrt(3*z**2 + rho**2)\n",
    "    p=z*np.cos(psi) - x*np.sin(psi)\n",
    "    Br=M_0/rho**5\n",
    "    bx=-Br*(- rho**2 *np.sin(psi) - 3.*x*p)\n",
    "    by= Br*(3.*y*p)\n",
    "    bz=-Br*(rho**2 *np.cos(psi) - 3.*z*p)\n",
    "    return bx, by, bz\n",
    "\n",
    "\n",
    "def dipole_magnitude(coords, psi, offset_x, offset_y, offset_z):\n",
    "    bx, by, bz = dipole_profile(coords, psi, offset_x, offset_y, offset_z)\n",
    "    field_dipole = np.sqrt(bx**2 + by**2 + bz**2)\n",
    "    return field_dipole\n",
    "\n",
    "\n",
    "#dipole_profile(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_vs_dipole(nodes, orbit_no, aberrated=True, more_title=\"\", plot_enabled=True):\n",
    "    periapsis = nodes[nodes[\"TYPE\"]==1]\n",
    "    dt1 = periapsis.index[orbit_no] - pd.Timedelta(\"1h\")\n",
    "    dt2 = periapsis.index[orbit_no] + pd.Timedelta(\"1h\")\n",
    "    fragment = data[dt1 : dt2]\n",
    "    \n",
    "    if aberrated:\n",
    "        x, y, z = fragment[\"X_AB\"], fragment[\"Y_AB\"], fragment[\"Z_AB\"]\n",
    "        bx, by, bz = fragment[\"BX_AB\"], fragment[\"BY_AB\"], fragment[\"BZ_AB\"]\n",
    "        dbx, dby, dbz = fragment[\"DBX_AB\"], fragment[\"DBY_AB\"], fragment[\"DBZ_AB\"]\n",
    "        rho, rxy = fragment[\"RHO_AB\"], fragment[\"RXY_AB\"]\n",
    "    else:\n",
    "        x, y, z = fragment[\"X_MSO\"], fragment[\"Y_MSO\"], fragment[\"Z_MSO\"]\n",
    "        bx, by, bz = fragment[\"BX_MSO\"], fragment[\"BY_MSO\"], fragment[\"BZ_MSO\"]\n",
    "        dbx, dby, dbz = fragment[\"DBX_MSO\"], fragment[\"DBY_MSO\"], fragment[\"DBZ_MSO\"]\n",
    "        rho, rxy = fragment[\"RHO\"], fragment[\"RXY\"]\n",
    "    \n",
    "    coords = pd.concat([x, y, z], axis=1)\n",
    "    field_exp = np.sqrt(bx**2 + by**2 + bz**2)\n",
    "    \n",
    "    popt, pcov = curve_fit(dipole_magnitude, coords, field_exp)\n",
    "    #print(popt)\n",
    "    dipolex, dipoley, dipolez = dipole_profile(coords, popt[0], popt[1], popt[2], popt[3])\n",
    "    #fragment['BX_DIPOLE'], fragment['BY_DIPOLE'], fragment['BZ_DIPOLE']\n",
    "    \n",
    "    \n",
    "    field_dipole = np.sqrt(dipolex**2 + dipoley**2 + dipolez**2) # fragment['BABS_DIPOLE']\n",
    "    \n",
    "    #print(field_exp.idxmax(), field_dipole.idxmax())\n",
    "    if plot_enabled:\n",
    "        plt.plot(field_exp, color='b')\n",
    "        plt.plot(field_dipole, color='g')\n",
    "        plt.plot(fragment['RHO_DIPOLE']/100, color='k')\n",
    "        plt.xlabel(\"Время\")\n",
    "        plt.ylabel(\"Магнитное поле [нТл]\")\n",
    "        plt.gca().xaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "        plt.gca().xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    return \n",
    "\n",
    "dipole_params = []\n",
    "\n",
    "for i in range(0, 4000):\n",
    "    dipole_params.append(exp_vs_dipole(nodes, i, ab, \"\", False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "from datetime import datetime\n",
    "from matplotlib import dates\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator, LinearLocator, AutoLocator\n",
    "import matplotlib as mpl\n",
    "\n",
    "base_name = \"MAGMSOSCIAVG%s%03d_%s_V06.TAB\"\n",
    "data_limits = { 2011: [82, 365], 2012: [1, 366], 2013: [1, 365], 2014: [1, 365], 2015: [1, 120] }\n",
    "\n",
    "def advanced_plot(pictype, data, normalize=False, more_title=\"\"):\n",
    "    data_np=data.as_matrix().T\n",
    "    x, y, z = data_np[0], data_np[1], data_np[2]\n",
    "    if normalize:\n",
    "        bx, by, bz = data_np[3] - data_np[-3], data_np[4] - data_np[-2], data_np[5] - data_np[-1]\n",
    "    else:\n",
    "        bx, by, bz = data_np[3], data_np[4], data_np[5]\n",
    "    dbx, dby, dbz = data_np[6], data_np[7], data_np[8]\n",
    "    # We drop the last record from the input file as it belongs to the next day\n",
    "    timex = map(lambda dt64: datetime.utcfromtimestamp((dt64 - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')), data.index.values)\n",
    "\n",
    "    if pictype == \"bfield\":\n",
    "        data = np.vstack([bx, by, bz])\n",
    "        err  = np.vstack([dbx, dby, dbz])\n",
    "        babs = np.apply_along_axis(lambda p: np.sqrt(sum(p**2)), 0, data)\n",
    "    elif pictype == \"coord\":\n",
    "        data = np.vstack([x, y, z])\n",
    "        err  = 0.0\n",
    "    \n",
    "    lo, hi = data - err, data + err\n",
    "    data, lo, hi = data, lo, hi\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    plt.grid(which='minor')\n",
    "    plt.grid(which='major')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=\"vertical\")\n",
    "    plt.subplots_adjust(bottom=.3)\n",
    "    plt.title(\"%s :: %s\" % (timex[0].strftime(\"%Y-%m-%d\"), more_title))\n",
    "\n",
    "\n",
    "    labels = { \"coord\": [\"x\", \"y\", \"z\"], \"bfield\": [\"Bx\", \"By\", \"Bz\"]}\n",
    "    colors = [\"blue\", \"magenta\", \"red\"]\n",
    "\n",
    "    lines = []\n",
    "    for i in range(data.shape[0]):\n",
    "        line = plt.plot(ax, timex, data[i], label=labels[pictype][i], color=colors[i])\n",
    "        lines.append(line)\n",
    "        plt.fill_between(timex, lo[i], hi[i], facecolor=colors[i], interpolate=True, alpha=0.3, color=\"none\", edgecolor=\"k\", linewidth=0.0)\n",
    "\n",
    "    if pictype == 'bfield':\n",
    "        plt.plot(ax, timex, babs, color='k', linewidth=1.4)\n",
    "        plt.plot(ax, timex, -babs, color='k', linewidth=1.4)\n",
    "        diffax = ax.twinx()\n",
    "        deltab = np.apply_along_axis(lambda p: np.sqrt(sum(p**2)), 0, np.diff(data, axis=1))\n",
    "        line = diffax.plot(timex[:-1], deltab, color='green', label=r'$\\Delta$B')\n",
    "        lines.append(line)\n",
    "        for tl in diffax.get_yticklabels():\n",
    "            tl.set_color('green')\n",
    "        ax.set_ylabel(r'$B$ [nT]', color='k')\n",
    "        diffax.set_ylabel(r'$|\\Delta B|$ [nT]', color='green')\n",
    "        lines = lines[0] + lines[1] + lines[2] + lines[3]\n",
    "    else:\n",
    "        ax.set_ylabel(r'Distance to Mercury center [km]', color='k')\n",
    "        lines = lines[0] + lines[1] + lines[2]\n",
    "\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax.legend(lines, labels, loc=1)\n",
    "\n",
    "\n",
    "def a2000_vs_dipole_plot(data, component):\n",
    "    data_np=data.as_matrix().T\n",
    "    x, y, z = data_np[0], data_np[1], data_np[2]\n",
    "    if component == \"x\":\n",
    "        bx, by, bz = data_np[3], data_np[-3], data_np[3] - data_np[-3]\n",
    "    elif component == \"y\":\n",
    "        bx, by, bz = data_np[4], data_np[-2], data_np[4] - data_np[-2]\n",
    "    elif component == \"z\":\n",
    "        bx, by, bz = data_np[5], data_np[-1], data_np[5] - data_np[-1]\n",
    "    dbx, dby, dbz = data_np[6], data_np[7], data_np[8]\n",
    "    # We drop the last record from the input file as it belongs to the next day\n",
    "    timex = map(lambda dt64: datetime.utcfromtimestamp((dt64 - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')), data.index.values)\n",
    "\n",
    "    data = np.vstack([bx, by, bz])\n",
    "    err  = np.vstack([dbx, dby, dbz])\n",
    "    babs = np.apply_along_axis(lambda p: np.sqrt(sum(p**2)), 0, data)\n",
    "    \n",
    "    lo, hi = data - err, data + err\n",
    "    data, lo, hi = data, lo, hi\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    plt.grid(which='minor')\n",
    "    plt.grid(which='major')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=\"vertical\")\n",
    "    plt.subplots_adjust(bottom=.3)\n",
    "    plt.title(timex[0].strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "    labels = { \"bfield\": [\"$B_{data}$\", \"$B_{dipole}$\", \"$\\Delta B$\"]}\n",
    "    colors = [\"red\", \"blue\", \"magenta\"]\n",
    "\n",
    "    lines = []\n",
    "    for i in range(data.shape[0]):\n",
    "        line = ppl.plot(ax, timex, data[i], label=labels[\"bfield\"][i], color=colors[i])\n",
    "        lines.append(line)\n",
    "        ppl.fill_between(timex, lo[i], hi[i], facecolor=colors[i], interpolate=True, alpha=0.3, color=\"none\", edgecolor=\"k\", linewidth=0.0)\n",
    "\n",
    "    ax.set_ylabel(r'$B$ [nT]', color='k')\n",
    "    lines = lines[0] + lines[1] + lines[2]\n",
    "\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax.legend(lines, labels, loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed(data):\n",
    "    data.to_csv(\"/home/dp/messenger/uru/data_disser.csv\")\n",
    "# save_preprocessed(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/home/dp/messenger/uru/data_disser.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_orbit_section(base_cos, cos_spread):\n",
    "    threshold = np.where((cos_array < base_cos+cos_spread) & (cos_array > base_cos-cos_spread))[0]\n",
    "    return np.array(list(set(np.where(cerc_vec==-1)[0]).intersection(threshold)))\n",
    "        \n",
    "def compare_approach_types():\n",
    "    cos_spread = 0.002\n",
    "    for base_cos in np.arange(-0.95, 0.95, 0.05):\n",
    "        closest_approaches = select_orbit_section(base_cos, cos_spread)\n",
    "        for appr in closest_approaches[:1]:\n",
    "            advanced_plot(\"bfield\", data_ab[dt[appr-spread]:dt[appr+spread]], True, base_cos)\n",
    "            advanced_plot(\"coord\", data_ab[dt[appr-spread]:dt[appr+spread]], False, base_cos)\n",
    "        \n",
    "def get_x_spread(approaches):\n",
    "    deltas = []\n",
    "    for appr in approaches:\n",
    "        _min = data_ab[\"X_MSO\"][dt[appr-spread]:dt[appr+spread]].min()\n",
    "        _max = data_ab[\"X_MSO\"][dt[appr-spread]:dt[appr+spread]].max()\n",
    "        deltas.append(_max - _min)\n",
    "    return reduce(lambda x, y: x + y, deltas) / len(deltas)\n",
    "    \n",
    "# Selected manually to achieve minimum X_MSO spread between points of entry and departure\n",
    "base_cos = 0.0\n",
    "cos_spread = 0.3\n",
    "\n",
    "#for cos_spread in np.arange(0.1, 0.9, 0.1):\n",
    "#    closest_approaches = select_orbit_section(base_cos, cos_spread)\n",
    "#    print cos_spread, len(closest_approaches)*1.0/np.where(cerc_vec==-1)[0].shape[0], get_x_spread(closest_approaches)\n",
    "\n",
    "# Number of points around each closest approach\n",
    "spread = 100\n",
    "closest_approaches = select_orbit_section(base_cos, cos_spread)\n",
    "f1 = open(\"orbits-times.txt\", \"w\")\n",
    "f2 = open(\"orbits-to-cluster.csv\", \"w\")\n",
    "for appr in closest_approaches:\n",
    "    df1 = data_ab[[\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]][dt[appr-spread]:dt[appr+spread]]\n",
    "    df2 = data_ab[[\"B_X\", \"B_Y\", \"B_Z\"]][dt[appr-spread]:dt[appr+spread]]\n",
    "    df = df1[[\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]]\n",
    "    df['BX_MSO'] = df1.BX_MSO - df2.B_X\n",
    "    df['BY_MSO'] = df1.BY_MSO - df2.B_Y\n",
    "    df['BZ_MSO'] = df1.BZ_MSO - df2.B_Z\n",
    "    if not df.isnull().any().any():\n",
    "        f2.write(\",\".join(map(lambda x: str(x), df.values.flatten(order='F'))))\n",
    "        f2.write(\"\\n\")\n",
    "        f1.write(str(data_ab[[\"BX_MSO\", \"BY_MSO\", \"BZ_MSO\"]][dt[appr]:dt[appr]].index.values[0]))\n",
    "        f1.write(\"\\n\")\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periapsis, apoapsis = argrelextrema(data['RHO_DIPOLE'].values, np.greater), argrelextrema(data['RHO_DIPOLE'].values, np.less)\n",
    "\n",
    "peri = data.iloc[periapsis];\n",
    "babs = np.sqrt(peri.BX_AB**2 + peri.BY_AB**2 + peri.BZ_AB**2)\n",
    "\n",
    "apo = data.iloc[apoapsis];\n",
    "babs = np.sqrt(apo.BX_AB**2 + apo.BY_AB**2 + apo.BZ_AB**2)\n",
    "\n",
    "plt.hist(babs[~np.isnan(babs)], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
